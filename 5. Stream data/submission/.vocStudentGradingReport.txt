
[Executed at: Wed Jul 1 9:38:18 PDT 2020]

==================================================
Task 1 (python) runtime (ms), 27271
Task 1: 4.5 out of 4.5
==================================================
Task 2: 4.5 out of 4.5
==================================================
Task 3: 0. out of 3.5
==================================================
Task 1 Scala:
==================================================
task2.scala not found
Task 2 Scala:  0.0
==================================================

2020-07-01 09:32:50 WARN  Utils:66 - Your hostname, ip-172-31-26-178 resolves to a loopback address: 127.0.0.1; using 172.31.26.178 instead (on interface ens5)
2020-07-01 09:32:50 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2020-07-01 09:32:51 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-01 09:32:54 INFO  SparkContext:54 - Running Spark version 2.3.0
2020-07-01 09:32:54 INFO  SparkContext:54 - Submitted application: task1.py
2020-07-01 09:32:54 INFO  SecurityManager:54 - Changing view acls to: ccc_v1_g_6fc4f_13621
2020-07-01 09:32:54 INFO  SecurityManager:54 - Changing modify acls to: ccc_v1_g_6fc4f_13621
2020-07-01 09:32:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-07-01 09:32:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-07-01 09:32:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_6fc4f_13621); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_6fc4f_13621); groups with modify permissions: Set()
2020-07-01 09:32:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 34669.
2020-07-01 09:32:55 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-07-01 09:32:55 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-07-01 09:32:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-07-01 09:32:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-07-01 09:32:55 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-0e9dde7b-374d-4571-be6d-18498efb97da
2020-07-01 09:32:55 INFO  MemoryStore:54 - MemoryStore started with capacity 2004.6 MB
2020-07-01 09:32:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-07-01 09:32:55 INFO  log:192 - Logging initialized @14902ms
2020-07-01 09:32:55 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2020-07-01 09:32:55 INFO  Server:414 - Started @15033ms
2020-07-01 09:32:55 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2020-07-01 09:32:55 INFO  AbstractConnector:278 - Started ServerConnector@3f463026{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2020-07-01 09:32:55 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4041.
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f89a6a5{/jobs,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12023b07{/jobs/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d642fbf{/jobs/job,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@750ec166{/jobs/job/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@76d716c3{/stages,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a72d671{/stages/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e4b102b{/stages/stage,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f7f0442{/stages/stage/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49a39dce{/stages/pool,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ba7e7ca{/stages/pool/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c8a43ac{/storage,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5bf0056b{/storage/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@e68ae36{/storage/rdd,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a259186{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@749c2e4d{/environment,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f9ca6e8{/environment/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@644eb433{/executors,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1291b09d{/executors/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ea1ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d0b4737{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cf59d89{/static,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5bfdfc3d{/,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ed30ae1{/api,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@26682a4c{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39799883{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-07-01 09:32:55 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://172.31.26.178:4041
2020-07-01 09:32:56 INFO  SparkContext:54 - Added file file:/home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py at file:/home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py with timestamp 1593621176243
2020-07-01 09:32:56 INFO  Utils:54 - Copying /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py to /tmp/spark-e5ee8b38-87bb-46df-ac09-c61444fce9d7/userFiles-c636b961-6e2c-4e7b-acd3-f6c60bee0cb1/task1.py
2020-07-01 09:32:56 INFO  Executor:54 - Starting executor ID driver on host localhost
2020-07-01 09:32:56 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41444.
2020-07-01 09:32:56 INFO  NettyBlockTransferService:54 - Server created on 172.31.26.178:41444
2020-07-01 09:32:56 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-07-01 09:32:56 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 172.31.26.178, 41444, None)
2020-07-01 09:32:56 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.31.26.178:41444 with 2004.6 MB RAM, BlockManagerId(driver, 172.31.26.178, 41444, None)
2020-07-01 09:32:56 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 172.31.26.178, 41444, None)
2020-07-01 09:32:56 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 172.31.26.178, 41444, None)
2020-07-01 09:32:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c4e84f5{/metrics/json,null,AVAILABLE,@Spark}
2020-07-01 09:32:57 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 236.5 KB, free 2004.4 MB)
2020-07-01 09:32:57 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 2004.3 MB)
2020-07-01 09:32:57 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 172.31.26.178:41444 (size: 22.9 KB, free: 2004.6 MB)
2020-07-01 09:32:57 INFO  SparkContext:54 - Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
2020-07-01 09:32:57 INFO  FileInputFormat:249 - Total input paths to process : 1
2020-07-01 09:32:57 INFO  SparkContext:54 - Starting job: collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21)
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Got job 0 (collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21) with 3 output partitions
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21)
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (PairwiseRDD[3] at distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21), which has no missing parents
2020-07-01 09:32:57 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.3 KB, free 2004.3 MB)
2020-07-01 09:32:57 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2004.3 MB)
2020-07-01 09:32:57 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 172.31.26.178:41444 (size: 6.1 KB, free: 2004.6 MB)
2020-07-01 09:32:57 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2020-07-01 09:32:57 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21) (first 15 tasks are for partitions Vector(0, 1, 2))
2020-07-01 09:32:57 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 3 tasks
2020-07-01 09:32:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7933 bytes)
2020-07-01 09:32:57 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7933 bytes)
2020-07-01 09:32:57 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7933 bytes)
2020-07-01 09:32:57 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2020-07-01 09:32:57 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2020-07-01 09:32:57 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2020-07-01 09:32:57 INFO  Executor:54 - Fetching file:/home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py with timestamp 1593621176243
2020-07-01 09:32:57 INFO  Utils:54 - /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py has been previously copied to /tmp/spark-e5ee8b38-87bb-46df-ac09-c61444fce9d7/userFiles-c636b961-6e2c-4e7b-acd3-f6c60bee0cb1/task1.py
2020-07-01 09:32:57 INFO  HadoopRDD:54 - Input split: file:/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/publicdata/business_second.json:67108864+5939966
2020-07-01 09:32:57 INFO  HadoopRDD:54 - Input split: file:/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/publicdata/business_second.json:33554432+33554432
2020-07-01 09:32:57 INFO  HadoopRDD:54 - Input split: file:/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/publicdata/business_second.json:0+33554432
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 824, boot = 428, init = 26, finish = 370
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 2148, boot = 421, init = 45, finish = 1682
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 2173, boot = 424, init = 14, finish = 1735
2020-07-01 09:33:00 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1613 bytes result sent to driver
2020-07-01 09:33:00 INFO  Executor:54 - Finished task 2.0 in stage 0.0 (TID 2). 1613 bytes result sent to driver
2020-07-01 09:33:00 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1570 bytes result sent to driver
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 0.0 (TID 2) in 2470 ms on localhost (executor driver) (1/3)
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 2494 ms on localhost (executor driver) (2/3)
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 2479 ms on localhost (executor driver) (3/3)
2020-07-01 09:33:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2020-07-01 09:33:00 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21) finished in 2.585 s
2020-07-01 09:33:00 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-07-01 09:33:00 INFO  DAGScheduler:54 - running: Set()
2020-07-01 09:33:00 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2020-07-01 09:33:00 INFO  DAGScheduler:54 - failed: Set()
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Submitting ResultStage 1 (PythonRDD[6] at collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21), which has no missing parents
2020-07-01 09:33:00 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 6.6 KB, free 2004.3 MB)
2020-07-01 09:33:00 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2004.3 MB)
2020-07-01 09:33:00 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 172.31.26.178:41444 (size: 4.2 KB, free: 2004.6 MB)
2020-07-01 09:33:00 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 1 (PythonRDD[6] at collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21) (first 15 tasks are for partitions Vector(0, 1, 2))
2020-07-01 09:33:00 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 3 tasks
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 3, localhost, executor driver, partition 0, ANY, 7649 bytes)
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 4, localhost, executor driver, partition 1, ANY, 7649 bytes)
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 5, localhost, executor driver, partition 2, ANY, 7649 bytes)
2020-07-01 09:33:00 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 3)
2020-07-01 09:33:00 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 5)
2020-07-01 09:33:00 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 4)
2020-07-01 09:33:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:00 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 7 ms
2020-07-01 09:33:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 7 ms
2020-07-01 09:33:00 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 7 ms
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 12, boot = -233, init = 244, finish = 1
2020-07-01 09:33:00 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 5). 6668 bytes result sent to driver
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 38, boot = -1463, init = 1500, finish = 1
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 5) in 83 ms on localhost (executor driver) (1/3)
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 26, boot = -216, init = 241, finish = 1
2020-07-01 09:33:00 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 4). 6707 bytes result sent to driver
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 4) in 94 ms on localhost (executor driver) (2/3)
2020-07-01 09:33:00 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 3). 6247 bytes result sent to driver
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 3) in 110 ms on localhost (executor driver) (3/3)
2020-07-01 09:33:00 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2020-07-01 09:33:00 INFO  DAGScheduler:54 - ResultStage 1 (collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21) finished in 0.134 s
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Job 0 finished: collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:21, took 2.781805 s
2020-07-01 09:33:00 INFO  SparkContext:54 - Starting job: collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Registering RDD 8 (distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25)
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Registering RDD 12 (distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25)
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Got job 1 (collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) with 3 output partitions
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25)
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 3)
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 3)
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (PairwiseRDD[8] at distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25), which has no missing parents
2020-07-01 09:33:00 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 9.3 KB, free 2004.3 MB)
2020-07-01 09:33:00 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2004.3 MB)
2020-07-01 09:33:00 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 172.31.26.178:41444 (size: 6.1 KB, free: 2004.6 MB)
2020-07-01 09:33:00 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2020-07-01 09:33:00 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ShuffleMapStage 2 (PairwiseRDD[8] at distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) (first 15 tasks are for partitions Vector(0, 1, 2))
2020-07-01 09:33:00 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 3 tasks
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7933 bytes)
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 7933 bytes)
2020-07-01 09:33:00 INFO  TaskSetManager:54 - Starting task 2.0 in stage 2.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 7933 bytes)
2020-07-01 09:33:00 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 6)
2020-07-01 09:33:00 INFO  Executor:54 - Running task 2.0 in stage 2.0 (TID 8)
2020-07-01 09:33:00 INFO  HadoopRDD:54 - Input split: file:/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/publicdata/business_second.json:0+33554432
2020-07-01 09:33:00 INFO  HadoopRDD:54 - Input split: file:/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/publicdata/business_second.json:67108864+5939966
2020-07-01 09:33:00 INFO  Executor:54 - Running task 1.0 in stage 2.0 (TID 7)
2020-07-01 09:33:00 INFO  HadoopRDD:54 - Input split: file:/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/publicdata/business_second.json:33554432+33554432
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 12
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 45
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 16
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 33
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 42
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 40
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 14
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 23
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 41
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 32
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 25
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 6
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 4
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 21
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 26
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 5
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 22
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 28
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 44
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 11
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 37
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 8
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 48
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 7
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 46
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 29
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 9
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 10
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 27
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 31
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 36
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 34
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 47
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 3
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 49
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 17
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 1
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 50
2020-07-01 09:33:00 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on 172.31.26.178:41444 in memory (size: 4.2 KB, free: 2004.6 MB)
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 15
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 30
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 18
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 38
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 13
2020-07-01 09:33:00 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 172.31.26.178:41444 in memory (size: 6.1 KB, free: 2004.6 MB)
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 19
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 24
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 2
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 43
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 35
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 39
2020-07-01 09:33:00 INFO  ContextCleaner:54 - Cleaned accumulator 20
2020-07-01 09:33:00 INFO  PythonRunner:54 - Times: total = 386, boot = -164, init = 181, finish = 369
2020-07-01 09:33:01 INFO  Executor:54 - Finished task 2.0 in stage 2.0 (TID 8). 1570 bytes result sent to driver
2020-07-01 09:33:01 INFO  TaskSetManager:54 - Finished task 2.0 in stage 2.0 (TID 8) in 420 ms on localhost (executor driver) (1/3)
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 1447, boot = -130, init = 145, finish = 1432
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 6). 1613 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 6) in 1497 ms on localhost (executor driver) (2/3)
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 1508, boot = -145, init = 184, finish = 1469
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 1.0 in stage 2.0 (TID 7). 1570 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 7) in 1542 ms on localhost (executor driver) (3/3)
2020-07-01 09:33:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2020-07-01 09:33:02 INFO  DAGScheduler:54 - ShuffleMapStage 2 (distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) finished in 1.556 s
2020-07-01 09:33:02 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-07-01 09:33:02 INFO  DAGScheduler:54 - running: Set()
2020-07-01 09:33:02 INFO  DAGScheduler:54 - waiting: Set(ShuffleMapStage 3, ResultStage 4)
2020-07-01 09:33:02 INFO  DAGScheduler:54 - failed: Set()
2020-07-01 09:33:02 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 3 (PairwiseRDD[12] at distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25), which has no missing parents
2020-07-01 09:33:02 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 9.8 KB, free 2004.3 MB)
2020-07-01 09:33:02 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.6 KB, free 2004.3 MB)
2020-07-01 09:33:02 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 172.31.26.178:41444 (size: 6.6 KB, free: 2004.6 MB)
2020-07-01 09:33:02 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2020-07-01 09:33:02 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ShuffleMapStage 3 (PairwiseRDD[12] at distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) (first 15 tasks are for partitions Vector(0, 1, 2))
2020-07-01 09:33:02 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 3 tasks
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 9, localhost, executor driver, partition 0, ANY, 7638 bytes)
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 10, localhost, executor driver, partition 1, ANY, 7638 bytes)
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Starting task 2.0 in stage 3.0 (TID 11, localhost, executor driver, partition 2, ANY, 7638 bytes)
2020-07-01 09:33:02 INFO  Executor:54 - Running task 2.0 in stage 3.0 (TID 11)
2020-07-01 09:33:02 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 9)
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-07-01 09:33:02 INFO  Executor:54 - Running task 1.0 in stage 3.0 (TID 10)
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 10, boot = -1141, init = 1147, finish = 4
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 2.0 in stage 3.0 (TID 11). 1742 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 2.0 in stage 3.0 (TID 11) in 39 ms on localhost (executor driver) (1/3)
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 18, boot = -46, init = 59, finish = 5
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 9). 1742 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 9) in 61 ms on localhost (executor driver) (2/3)
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 66, boot = -92, init = 153, finish = 5
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 1.0 in stage 3.0 (TID 10). 1742 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 10) in 103 ms on localhost (executor driver) (3/3)
2020-07-01 09:33:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2020-07-01 09:33:02 INFO  DAGScheduler:54 - ShuffleMapStage 3 (distinct at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) finished in 0.114 s
2020-07-01 09:33:02 INFO  DAGScheduler:54 - looking for newly runnable stages
2020-07-01 09:33:02 INFO  DAGScheduler:54 - running: Set()
2020-07-01 09:33:02 INFO  DAGScheduler:54 - waiting: Set(ResultStage 4)
2020-07-01 09:33:02 INFO  DAGScheduler:54 - failed: Set()
2020-07-01 09:33:02 INFO  DAGScheduler:54 - Submitting ResultStage 4 (PythonRDD[15] at collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25), which has no missing parents
2020-07-01 09:33:02 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 6.6 KB, free 2004.3 MB)
2020-07-01 09:33:02 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2004.3 MB)
2020-07-01 09:33:02 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 172.31.26.178:41444 (size: 4.2 KB, free: 2004.6 MB)
2020-07-01 09:33:02 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039
2020-07-01 09:33:02 INFO  DAGScheduler:54 - Submitting 3 missing tasks from ResultStage 4 (PythonRDD[15] at collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) (first 15 tasks are for partitions Vector(0, 1, 2))
2020-07-01 09:33:02 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 3 tasks
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 12, localhost, executor driver, partition 0, ANY, 7649 bytes)
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 13, localhost, executor driver, partition 1, ANY, 7649 bytes)
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 14, localhost, executor driver, partition 2, ANY, 7649 bytes)
2020-07-01 09:33:02 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 12)
2020-07-01 09:33:02 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 14)
2020-07-01 09:33:02 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 13)
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Getting 3 non-empty blocks out of 3 blocks
2020-07-01 09:33:02 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 44, boot = -79, init = 122, finish = 1
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 14). 3018 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 14) in 58 ms on localhost (executor driver) (1/3)
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 53, boot = -97, init = 149, finish = 1
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 12). 3146 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 12) in 67 ms on localhost (executor driver) (2/3)
2020-07-01 09:33:02 INFO  PythonRunner:54 - Times: total = 47, boot = -46, init = 92, finish = 1
2020-07-01 09:33:02 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 13). 3245 bytes result sent to driver
2020-07-01 09:33:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 13) in 76 ms on localhost (executor driver) (3/3)
2020-07-01 09:33:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2020-07-01 09:33:02 INFO  DAGScheduler:54 - ResultStage 4 (collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25) finished in 0.087 s
2020-07-01 09:33:02 INFO  DAGScheduler:54 - Job 1 finished: collect at /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task1.py:25, took 1.773014 s
array_bit:  1425
399
size of ans: 94296
[(371, -9146, 5801), (960, -4316, 10007)]
Duration:  10.295923233032227
2020-07-01 09:33:04 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2020-07-01 09:33:04 INFO  AbstractConnector:318 - Stopped Spark@3f463026{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2020-07-01 09:33:04 INFO  SparkUI:54 - Stopped Spark web UI at http://172.31.26.178:4041
2020-07-01 09:33:04 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2020-07-01 09:33:04 INFO  MemoryStore:54 - MemoryStore cleared
2020-07-01 09:33:04 INFO  BlockManager:54 - BlockManager stopped
2020-07-01 09:33:04 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2020-07-01 09:33:04 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2020-07-01 09:33:04 INFO  SparkContext:54 - Successfully stopped SparkContext
2020-07-01 09:33:04 INFO  ShutdownHookManager:54 - Shutdown hook called
2020-07-01 09:33:04 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-e5ee8b38-87bb-46df-ac09-c61444fce9d7/pyspark-1aa7e522-f8cb-40ac-84d0-70cd2cf49482
2020-07-01 09:33:04 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a817644d-4a65-4cb9-80d2-41138db8cc24
2020-07-01 09:33:04 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-e5ee8b38-87bb-46df-ac09-c61444fce9d7
2020-07-01 09:33:06 WARN  Utils:66 - Your hostname, ip-172-31-26-178 resolves to a loopback address: 127.0.0.1; using 172.31.26.178 instead (on interface ens5)
2020-07-01 09:33:06 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
Exception in thread "main" java.net.BindException: Address already in use (Bind failed)
	at java.net.PlainSocketImpl.socketBind(Native Method)
	at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:387)
	at java.net.ServerSocket.bind(ServerSocket.java:375)
	at java.net.ServerSocket.<init>(ServerSocket.java:237)
	at java.net.ServerSocket.<init>(ServerSocket.java:128)
	at StreamSimulation$.main(StreamSimulation.scala:34)
	at StreamSimulation.main(StreamSimulation.scala)
2020-07-01 09:33:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-01 09:33:07 INFO  SparkContext:54 - Running Spark version 2.3.0
2020-07-01 09:33:07 INFO  SparkContext:54 - Submitted application: task2.py
2020-07-01 09:33:08 INFO  SecurityManager:54 - Changing view acls to: ccc_v1_g_6fc4f_13621
2020-07-01 09:33:08 INFO  SecurityManager:54 - Changing modify acls to: ccc_v1_g_6fc4f_13621
2020-07-01 09:33:08 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-07-01 09:33:08 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-07-01 09:33:08 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_6fc4f_13621); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_6fc4f_13621); groups with modify permissions: Set()
2020-07-01 09:33:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35921.
2020-07-01 09:33:08 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-07-01 09:33:08 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-07-01 09:33:08 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-07-01 09:33:08 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-07-01 09:33:08 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-ef31cc2c-f1da-4ca4-8d3a-d2d0c44369ae
2020-07-01 09:33:08 INFO  MemoryStore:54 - MemoryStore started with capacity 2004.6 MB
2020-07-01 09:33:08 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-07-01 09:33:08 INFO  log:192 - Logging initialized @3149ms
2020-07-01 09:33:08 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2020-07-01 09:33:08 INFO  Server:414 - Started @3245ms
2020-07-01 09:33:08 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2020-07-01 09:33:08 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2020-07-01 09:33:08 INFO  AbstractConnector:278 - Started ServerConnector@7e7601b3{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2020-07-01 09:33:08 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4042.
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39663652{/jobs,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@270d2af8{/jobs/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@472392f8{/jobs/job,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1f44cdf6{/jobs/job/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51506e0c{/stages,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@abf928c{/stages/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d6243f6{/stages/stage,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70dfe5e3{/stages/stage/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@fdd75fd{/stages/pool,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5bbfc247{/stages/pool/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cc87d39{/storage,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433779be{/storage/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27219eb8{/storage/rdd,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a9cde1{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d875938{/environment,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75852bbf{/environment/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e7abfe9{/executors,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12f0a702{/executors/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@258962fd{/executors/threadDump,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@798d7d20{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7203000f{/static,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c2e61cf{/,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d1250ac{/api,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30e3fd45{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@c50d3fd{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-07-01 09:33:08 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://172.31.26.178:4042
2020-07-01 09:33:08 INFO  SparkContext:54 - Added file file:/home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task2.py at file:/home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task2.py with timestamp 1593621188860
2020-07-01 09:33:08 INFO  Utils:54 - Copying /home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/task2.py to /tmp/spark-e087293c-02df-44db-bb39-7e676ebd8a8f/userFiles-c39f992d-1d43-4c4d-82d9-5595e48f2de7/task2.py
2020-07-01 09:33:08 INFO  Executor:54 - Starting executor ID driver on host localhost
2020-07-01 09:33:08 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34502.
2020-07-01 09:33:08 INFO  NettyBlockTransferService:54 - Server created on 172.31.26.178:34502
2020-07-01 09:33:08 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-07-01 09:33:08 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 172.31.26.178, 34502, None)
2020-07-01 09:33:08 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.31.26.178:34502 with 2004.6 MB RAM, BlockManagerId(driver, 172.31.26.178, 34502, None)
2020-07-01 09:33:08 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 172.31.26.178, 34502, None)
2020-07-01 09:33:08 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 172.31.26.178, 34502, None)
2020-07-01 09:33:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c791ea5{/metrics/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:03 ERROR ReceiverTracker:70 - Deregistered receiver for stream 0: Restarting receiver with delay 2000ms: Socket data stream had no more data
2020-07-01 09:38:05 ERROR JobScheduler:91 - Error generating jobs for time 1593621485000 ms
py4j.Py4JException: Error while sending a command.
	at py4j.CallbackClient.sendCommand(CallbackClient.java:357)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:316)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy16.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonTransformedDStream.compute(PythonDStream.scala:246)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:122)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:121)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:121)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
Caused by: py4j.Py4JNetworkException
	at py4j.CallbackConnection.sendCommand(CallbackConnection.java:138)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:344)
	... 34 more
task3.py grading temporarily disabled
2020-07-01 09:38:06 WARN  Utils:66 - Your hostname, ip-172-31-26-178 resolves to a loopback address: 127.0.0.1; using 172.31.26.178 instead (on interface ens5)
2020-07-01 09:38:06 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2020-07-01 09:38:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-07-01 09:38:07 INFO  SparkContext:54 - Running Spark version 2.3.0
2020-07-01 09:38:07 INFO  SparkContext:54 - Submitted application: scala
2020-07-01 09:38:07 INFO  SecurityManager:54 - Changing view acls to: ccc_v1_g_6fc4f_13621
2020-07-01 09:38:07 INFO  SecurityManager:54 - Changing modify acls to: ccc_v1_g_6fc4f_13621
2020-07-01 09:38:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2020-07-01 09:38:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2020-07-01 09:38:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_6fc4f_13621); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_6fc4f_13621); groups with modify permissions: Set()
2020-07-01 09:38:07 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 37870.
2020-07-01 09:38:07 INFO  SparkEnv:54 - Registering MapOutputTracker
2020-07-01 09:38:07 INFO  SparkEnv:54 - Registering BlockManagerMaster
2020-07-01 09:38:07 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2020-07-01 09:38:07 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2020-07-01 09:38:07 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-17c12df8-0480-4a45-a60a-0dc93ef6f437
2020-07-01 09:38:07 INFO  MemoryStore:54 - MemoryStore started with capacity 2004.6 MB
2020-07-01 09:38:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2020-07-01 09:38:07 INFO  log:192 - Logging initialized @1608ms
2020-07-01 09:38:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2020-07-01 09:38:07 INFO  Server:414 - Started @1679ms
2020-07-01 09:38:07 INFO  AbstractConnector:278 - Started ServerConnector@62efd793{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2020-07-01 09:38:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ef8a8c3{/jobs,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@41382722{/jobs/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7dac3fd8{/jobs/job,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2102a4d5{/jobs/job/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@210386e0{/stages,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d4d3fe7{/stages/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65f87a2c{/stages/stage,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38875e7d{/stages/stage/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e886a5b{/stages/pool,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d816dde{/stages/pool/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e33c391{/storage,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c451c9c{/storage/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31c269fd{/storage/rdd,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@372b0d86{/storage/rdd/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@47747fb9{/environment,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3113a37{/environment/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@213e3629{/executors,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4e9658b5{/executors/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a7b6f69{/executors/threadDump,null,AVAILABLE,@Spark}
2020-07-01 09:38:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@20312893{/executors/threadDump/json,null,AVAILABLE,@Spark}
2020-07-01 09:38:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@70eecdc2{/static,null,AVAILABLE,@Spark}
2020-07-01 09:38:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49a64d82{/,null,AVAILABLE,@Spark}
2020-07-01 09:38:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@344561e0{/api,null,AVAILABLE,@Spark}
2020-07-01 09:38:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@52c8295b{/jobs/job/kill,null,AVAILABLE,@Spark}
2020-07-01 09:38:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@251f7d26{/stages/stage/kill,null,AVAILABLE,@Spark}
2020-07-01 09:38:08 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://172.31.26.178:4040
2020-07-01 09:38:08 INFO  SparkContext:54 - Added JAR file:/home/ccc_v1_g_6fc4f_13621/asn197451_14/asn197452_1/791500/128/work/hw5.jar at spark://172.31.26.178:37870/jars/hw5.jar with timestamp 1593621488052
2020-07-01 09:38:08 INFO  Executor:54 - Starting executor ID driver on host localhost
2020-07-01 09:38:08 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35869.
2020-07-01 09:38:08 INFO  NettyBlockTransferService:54 - Server created on 172.31.26.178:35869
2020-07-01 09:38:08 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2020-07-01 09:38:08 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 172.31.26.178, 35869, None)
2020-07-01 09:38:08 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.31.26.178:35869 with 2004.6 MB RAM, BlockManagerId(driver, 172.31.26.178, 35869, None)
2020-07-01 09:38:08 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 172.31.26.178, 35869, None)
2020-07-01 09:38:08 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 172.31.26.178, 35869, None)
2020-07-01 09:38:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@312afbc7{/metrics/json,null,AVAILABLE,@Spark}
Vector(((5422,-6380),804824051), ((-8149,9039),24670986))
count: 404
count of array bit: 1517
size of output: 94296
Duration: 5.979
Traceback (most recent call last):
  File "/home/ccc_v1_c_b9Go_203599/asn197451_14/asn197452_1/asnlib.0/grade/score_scala.py", line 4, in <module>
    score_s = float(sys.argv[2])
ValueError: could not convert string to float: 'wrong'
../resource/scripts/grade.sh: line 136: unexpected EOF while looking for matching `"'
../resource/scripts/grade.sh: line 139: syntax error: unexpected end of file
Command exited with non-zero status 1
